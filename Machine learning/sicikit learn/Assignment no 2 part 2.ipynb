{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c33aeba",
   "metadata": {},
   "source": [
    "# scikit-learn "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a14e70",
   "metadata": {},
   "source": [
    "Evaluate several classifiers on the Wine dataset using scikit-learn\n",
    "\n",
    "Ratio 60-40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e210943f",
   "metadata": {},
   "source": [
    "# Svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e147978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy on Test Set: 0.6805555555555556\n",
      "SVM Accuracy on Training Set: 0.6698113207547169\n",
      "SVM Cross-Validation Scores: [0.63888889 0.61111111 0.63888889 0.68571429 0.74285714]\n",
      "SVM Cross-Validation Scores percentage : [63.88888889 61.11111111 63.88888889 68.57142857 74.28571429]\n",
      "SVM Cross-Validation Mean Score: 0.6634920634920635\n",
      "SVM Cross-Validation Standard Deviation: 0.04636170738133653\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# Loading the dataset\n",
    "x, y = load_wine(return_X_y=True)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, train_size=0.6)\n",
    "\n",
    "# Support Vector Machine (SVM)\n",
    "clf_svm = SVC()\n",
    "clf_svm.fit(x_train, y_train)\n",
    "\n",
    "# Accuracy Scores\n",
    "svm_acc_test = clf_svm.score(x_test, y_test)\n",
    "svm_acc_train = clf_svm.score(x_train, y_train)\n",
    "\n",
    "# Cross-Validation\n",
    "cv_svm = cross_val_score(clf_svm, x, y, cv=5)\n",
    "\n",
    "# Printing Results\n",
    "print(\"SVM Accuracy on Test Set:\", svm_acc_test)\n",
    "print(\"SVM Accuracy on Training Set:\", svm_acc_train)\n",
    "print(\"SVM Cross-Validation Scores:\", cv_svm)\n",
    "print(\"SVM Cross-Validation Scores percentage :\", cv_svm * 100)\n",
    "print(\"SVM Cross-Validation Mean Score:\", cv_svm.mean())\n",
    "print(\"SVM Cross-Validation Standard Deviation:\", cv_svm.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11fc50f",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b6ab4ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy on Test Set: 0.8888888888888888\n",
      "Decision Tree Accuracy on Training Set: 1.0\n",
      "Decision Tree Cross-Validation Scores: [0.91666667 0.77777778 0.91666667 0.91428571 0.82857143]\n",
      "Decision Tree Cross-Validation Mean Score: 0.8707936507936507\n",
      "Decision Tree Cross-Validation Standard Deviation: 0.05750633954557937\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Loading the dataset\n",
    "x, y = load_wine(return_X_y=True)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, train_size=0.6)\n",
    "\n",
    "# Decision Tree\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(x_train, y_train)\n",
    "\n",
    "# Accuracy Scores\n",
    "dt_acc_test = dt.score(x_test, y_test)\n",
    "dt_acc_train = dt.score(x_train, y_train)\n",
    "\n",
    "# Cross-Validation\n",
    "cv_dt = cross_val_score(dt, x, y, cv=5)\n",
    "\n",
    "# Printing Results\n",
    "print(\"Decision Tree Accuracy on Test Set:\", dt_acc_test)\n",
    "print(\"Decision Tree Accuracy on Training Set:\", dt_acc_train)\n",
    "print(\"Decision Tree Cross-Validation Scores:\", cv_dt)\n",
    "print(\"Decision Tree Cross-Validation Mean Score:\", cv_dt.mean())\n",
    "print(\"Decision Tree Cross-Validation Standard Deviation:\", cv_dt.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f531b6",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f72c04df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy on Test Set: 0.9861111111111112\n",
      "Random Forest Accuracy on Training Set: 1.0\n",
      "Random Forest Cross-Validation Scores: [0.95555556 0.93333333 0.97727273 1.        ]\n",
      "Random Forest Cross-Validation Mean Score: 0.966540404040404\n",
      "Random Forest Cross-Validation Standard Deviation: 0.02478963374538814\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# Loading the dataset\n",
    "x, y = load_wine(return_X_y=True)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, train_size=0.6)\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Accuracy Scores\n",
    "rf_acc_test = rf.score(x_test, y_test)\n",
    "rf_acc_train = rf.score(x_train, y_train)\n",
    "\n",
    "# Cross-Validation\n",
    "cv_rf = cross_val_score(rf, x, y, cv=4)\n",
    "\n",
    "# Printing Results\n",
    "print(\"Random Forest Accuracy on Test Set:\", rf_acc_test)\n",
    "print(\"Random Forest Accuracy on Training Set:\", rf_acc_train)\n",
    "print(\"Random Forest Cross-Validation Scores:\", cv_rf)\n",
    "print(\"Random Forest Cross-Validation Mean Score:\", cv_rf.mean())\n",
    "print(\"Random Forest Cross-Validation Standard Deviation:\", cv_rf.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acff8afb",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5a8bff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy on Test Set: 0.9305555555555556\n",
      "Logistic Regression Accuracy on Training Set: 0.9905660377358491\n",
      "Logistic Regression Cross-Validation Scores: [0.76666667 0.94915254 1.        ]\n",
      "Logistic Regression Cross-Validation Mean Score: 0.9052730696798493\n",
      "Logistic Regression Cross-Validation Standard Deviation: 0.1001837219112134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arooj\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Arooj\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Arooj\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Arooj\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# Loading the dataset\n",
    "x, y = load_wine(return_X_y=True)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, train_size=0.6)\n",
    "\n",
    "# Logistic Regression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(x_train, y_train)\n",
    "\n",
    "# Accuracy Scores\n",
    "lr_acc_test = lr.score(x_test, y_test)\n",
    "lr_acc_train = lr.score(x_train, y_train)\n",
    "\n",
    "# Cross-Validation\n",
    "cv_lr = cross_val_score(lr, x, y, cv=3)\n",
    "\n",
    "# Printing Results\n",
    "print(\"Logistic Regression Accuracy on Test Set:\", lr_acc_test)\n",
    "print(\"Logistic Regression Accuracy on Training Set:\", lr_acc_train)\n",
    "print(\"Logistic Regression Cross-Validation Scores:\", cv_lr)\n",
    "print(\"Logistic Regression Cross-Validation Mean Score:\", cv_lr.mean())\n",
    "print(\"Logistic Regression Cross-Validation Standard Deviation:\", cv_lr.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b2e85e",
   "metadata": {},
   "source": [
    "# GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72f3e88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy on Test Set: 0.9444444444444444\n",
      "Naive Bayes Accuracy on Training Set: 0.9905660377358491\n",
      "Naive Bayes Cross-Validation Scores: [0.94444444 0.97222222 0.97222222 0.94285714 1.        ]\n",
      "Naive Bayes Cross-Validation Mean Score: 0.9663492063492063\n",
      "Naive Bayes Cross-Validation Standard Deviation: 0.02113317858457236\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# Loading the dataset\n",
    "x, y = load_wine(return_X_y=True)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, train_size=0.6)\n",
    "\n",
    "# Naive Bayes\n",
    "nb = GaussianNB()\n",
    "nb.fit(x_train, y_train)\n",
    "\n",
    "# Accuracy Scores\n",
    "nb_acc_test = nb.score(x_test, y_test)\n",
    "nb_acc_train = nb.score(x_train, y_train)\n",
    "\n",
    "# Cross-Validation\n",
    "cv_nb = cross_val_score(nb, x, y, cv=5)\n",
    "\n",
    "# Printing Results\n",
    "print(\"Naive Bayes Accuracy on Test Set:\", nb_acc_test)\n",
    "print(\"Naive Bayes Accuracy on Training Set:\", nb_acc_train)\n",
    "print(\"Naive Bayes Cross-Validation Scores:\", cv_nb)\n",
    "print(\"Naive Bayes Cross-Validation Mean Score:\", cv_nb.mean())\n",
    "print(\"Naive Bayes Cross-Validation Standard Deviation:\", cv_nb.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309d5120",
   "metadata": {},
   "source": [
    "# K Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e5e34ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors Accuracy on Test Set: 0.6666666666666666\n",
      "K-Nearest Neighbors Accuracy on Training Set: 0.8018867924528302\n",
      "K-Nearest Neighbors Cross-Validation Scores: [0.72222222 0.66666667 0.63888889 0.65714286 0.77142857]\n",
      "K-Nearest Neighbors Cross-Validation Mean Score: 0.6912698412698413\n",
      "K-Nearest Neighbors Cross-Validation Standard Deviation: 0.04877951071049148\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# Loading the dataset\n",
    "x, y = load_wine(return_X_y=True)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, train_size=0.6)\n",
    "\n",
    "# K-Nearest Neighbors (KNN)\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(x_train, y_train)\n",
    "\n",
    "# Accuracy Scores\n",
    "knn_acc_test = knn.score(x_test, y_test)\n",
    "knn_acc_train = knn.score(x_train, y_train)\n",
    "\n",
    "# Cross-Validation\n",
    "cv_knn = cross_val_score(knn, x, y, cv=5)\n",
    "\n",
    "# Printing Results\n",
    "print(\"K-Nearest Neighbors Accuracy on Test Set:\", knn_acc_test)\n",
    "print(\"K-Nearest Neighbors Accuracy on Training Set:\", knn_acc_train)\n",
    "print(\"K-Nearest Neighbors Cross-Validation Scores:\", cv_knn)\n",
    "print(\"K-Nearest Neighbors Cross-Validation Mean Score:\", cv_knn.mean())\n",
    "print(\"K-Nearest Neighbors Cross-Validation Standard Deviation:\", cv_knn.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cca69d",
   "metadata": {},
   "source": [
    "# AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1395f0d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Accuracy on Test Set: 0.9166666666666666\n",
      "AdaBoost Accuracy on Training Set: 1.0\n",
      "AdaBoost Cross-Validation Scores: [0.69444444 0.91666667 0.91666667 0.54285714 0.97142857]\n",
      "AdaBoost Cross-Validation Mean Score: 0.8084126984126984\n",
      "AdaBoost Cross-Validation Standard Deviation: 0.16341391258982924\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# Loading the dataset\n",
    "x, y = load_wine(return_X_y=True)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, train_size=0.6)\n",
    "\n",
    "# AdaBoost\n",
    "adaboost = AdaBoostClassifier()\n",
    "adaboost.fit(x_train, y_train)\n",
    "\n",
    "# Accuracy Scores\n",
    "adaboost_acc_test = adaboost.score(x_test, y_test)\n",
    "adaboost_acc_train = adaboost.score(x_train, y_train)\n",
    "\n",
    "# Cross-Validation\n",
    "cv_adaboost = cross_val_score(adaboost, x, y, cv=5)\n",
    "\n",
    "# Printing Results\n",
    "print(\"AdaBoost Accuracy on Test Set:\", adaboost_acc_test)\n",
    "print(\"AdaBoost Accuracy on Training Set:\", adaboost_acc_train)\n",
    "print(\"AdaBoost Cross-Validation Scores:\", cv_adaboost)\n",
    "print(\"AdaBoost Cross-Validation Mean Score:\", cv_adaboost.mean())\n",
    "print(\"AdaBoost Cross-Validation Standard Deviation:\", cv_adaboost.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e06fc2",
   "metadata": {},
   "source": [
    "# Ratio 70-30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1233df",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20adc454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy on Test Set: 0.7777777777777778\n",
      "SVM Accuracy on Training Set: 0.6612903225806451\n",
      "SVM Cross-Validation Scores: [0.63888889 0.61111111 0.63888889 0.68571429 0.74285714]\n",
      "SVM Cross-Validation Scores percentage : [63.88888889 61.11111111 63.88888889 68.57142857 74.28571429]\n",
      "SVM Cross-Validation Mean Score: 0.6634920634920635\n",
      "SVM Cross-Validation Standard Deviation: 0.04636170738133653\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# Loading the dataset\n",
    "x, y = load_wine(return_X_y=True)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, train_size=0.7)\n",
    "\n",
    "# Support Vector Machine (SVM)\n",
    "clf_svm = SVC()\n",
    "clf_svm.fit(x_train, y_train)\n",
    "\n",
    "# Accuracy Scores\n",
    "svm_acc_test = clf_svm.score(x_test, y_test)\n",
    "svm_acc_train = clf_svm.score(x_train, y_train)\n",
    "\n",
    "# Cross-Validation\n",
    "cv_svm = cross_val_score(clf_svm, x, y, cv=5)\n",
    "\n",
    "# Printing Results\n",
    "print(\"SVM Accuracy on Test Set:\", svm_acc_test)\n",
    "print(\"SVM Accuracy on Training Set:\", svm_acc_train)\n",
    "print(\"SVM Cross-Validation Scores:\", cv_svm)\n",
    "print(\"SVM Cross-Validation Scores percentage :\", cv_svm * 100)\n",
    "print(\"SVM Cross-Validation Mean Score:\", cv_svm.mean())\n",
    "print(\"SVM Cross-Validation Standard Deviation:\", cv_svm.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfca89ae",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1fd576f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy on Test Set: 0.8703703703703703\n",
      "Decision Tree Accuracy on Training Set: 1.0\n",
      "Decision Tree Cross-Validation Scores: [0.88888889 0.83333333 0.86111111 0.91428571 0.85714286]\n",
      "Decision Tree Cross-Validation Mean Score: 0.8709523809523809\n",
      "Decision Tree Cross-Validation Standard Deviation: 0.027936507936507912\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Loading the dataset\n",
    "x, y = load_wine(return_X_y=True)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, train_size=0.7)\n",
    "\n",
    "# Decision Tree\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(x_train, y_train)\n",
    "\n",
    "# Accuracy Scores\n",
    "dt_acc_test = dt.score(x_test, y_test)\n",
    "dt_acc_train = dt.score(x_train, y_train)\n",
    "\n",
    "# Cross-Validation\n",
    "cv_dt = cross_val_score(dt, x, y, cv=5)\n",
    "\n",
    "# Printing Results\n",
    "print(\"Decision Tree Accuracy on Test Set:\", dt_acc_test)\n",
    "print(\"Decision Tree Accuracy on Training Set:\", dt_acc_train)\n",
    "print(\"Decision Tree Cross-Validation Scores:\", cv_dt)\n",
    "print(\"Decision Tree Cross-Validation Mean Score:\", cv_dt.mean())\n",
    "print(\"Decision Tree Cross-Validation Standard Deviation:\", cv_dt.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8a1ac9",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58f50bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy on Test Set: 0.9444444444444444\n",
      "Logistic Regression Accuracy on Training Set: 0.9838709677419355\n",
      "Logistic Regression Cross-Validation Scores: [0.76666667 0.94915254 1.        ]\n",
      "Logistic Regression Cross-Validation Mean Score: 0.9052730696798493\n",
      "Logistic Regression Cross-Validation Standard Deviation: 0.1001837219112134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arooj\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Arooj\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Arooj\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Arooj\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# Loading the dataset\n",
    "x, y = load_wine(return_X_y=True)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, train_size=0.7)\n",
    "\n",
    "# Logistic Regression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(x_train, y_train)\n",
    "\n",
    "# Accuracy Scores\n",
    "lr_acc_test = lr.score(x_test, y_test)\n",
    "lr_acc_train = lr.score(x_train, y_train)\n",
    "\n",
    "# Cross-Validation\n",
    "cv_lr = cross_val_score(lr, x, y, cv=3)\n",
    "\n",
    "# Printing Results\n",
    "print(\"Logistic Regression Accuracy on Test Set:\", lr_acc_test)\n",
    "print(\"Logistic Regression Accuracy on Training Set:\", lr_acc_train)\n",
    "print(\"Logistic Regression Cross-Validation Scores:\", cv_lr)\n",
    "print(\"Logistic Regression Cross-Validation Mean Score:\", cv_lr.mean())\n",
    "print(\"Logistic Regression Cross-Validation Standard Deviation:\", cv_lr.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcea92de",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0431b62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy on Test Set: 0.9629629629629629\n",
      "Random Forest Accuracy on Training Set: 1.0\n",
      "Random Forest Cross-Validation Scores: [0.9        0.89830508 1.        ]\n",
      "Random Forest Cross-Validation Mean Score: 0.932768361581921\n",
      "Random Forest Cross-Validation Standard Deviation: 0.04754498282478924\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# Loading the dataset\n",
    "x, y = load_wine(return_X_y=True)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, train_size=0.7)\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Accuracy Scores\n",
    "rf_acc_test = rf.score(x_test, y_test)\n",
    "rf_acc_train = rf.score(x_train, y_train)\n",
    "\n",
    "# Cross-Validation\n",
    "cv_rf = cross_val_score(rf, x, y, cv=3)\n",
    "\n",
    "# Printing Results\n",
    "print(\"Random Forest Accuracy on Test Set:\", rf_acc_test)\n",
    "print(\"Random Forest Accuracy on Training Set:\", rf_acc_train)\n",
    "print(\"Random Forest Cross-Validation Scores:\", cv_rf)\n",
    "print(\"Random Forest Cross-Validation Mean Score:\", cv_rf.mean())\n",
    "print(\"Random Forest Cross-Validation Standard Deviation:\", cv_rf.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb40b077",
   "metadata": {},
   "source": [
    "# GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6f4dca4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy on Test Set: 0.9444444444444444\n",
      "Naive Bayes Accuracy on Training Set: 0.9838709677419355\n",
      "Naive Bayes Cross-Validation Scores: [0.95       0.96610169 0.96610169]\n",
      "Naive Bayes Cross-Validation Mean Score: 0.9607344632768361\n",
      "Naive Bayes Cross-Validation Standard Deviation: 0.007590411775448826\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# Loading the dataset\n",
    "x, y = load_wine(return_X_y=True)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, train_size=0.7)\n",
    "\n",
    "# Naive Bayes\n",
    "nb = GaussianNB()\n",
    "nb.fit(x_train, y_train)\n",
    "\n",
    "# Accuracy Scores\n",
    "nb_acc_test = nb.score(x_test, y_test)\n",
    "nb_acc_train = nb.score(x_train, y_train)\n",
    "\n",
    "# Cross-Validation\n",
    "cv_nb = cross_val_score(nb, x, y, cv=3)\n",
    "\n",
    "# Printing Results\n",
    "print(\"Naive Bayes Accuracy on Test Set:\", nb_acc_test)\n",
    "print(\"Naive Bayes Accuracy on Training Set:\", nb_acc_train)\n",
    "print(\"Naive Bayes Cross-Validation Scores:\", cv_nb)\n",
    "print(\"Naive Bayes Cross-Validation Mean Score:\", cv_nb.mean())\n",
    "print(\"Naive Bayes Cross-Validation Standard Deviation:\", cv_nb.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3033a33",
   "metadata": {},
   "source": [
    "# KNeighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e7f10394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors Accuracy on Test Set: 0.7222222222222222\n",
      "K-Nearest Neighbors Accuracy on Training Set: 0.7903225806451613\n",
      "K-Nearest Neighbors Cross-Validation Scores: [0.61666667 0.61016949 0.76271186]\n",
      "K-Nearest Neighbors Cross-Validation Mean Score: 0.6631826741996234\n",
      "K-Nearest Neighbors Cross-Validation Standard Deviation: 0.07042773174762534\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# Loading the dataset\n",
    "x, y = load_wine(return_X_y=True)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, train_size=0.7)\n",
    "\n",
    "# K-Nearest Neighbors (KNN)\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(x_train, y_train)\n",
    "\n",
    "# Accuracy Scores\n",
    "knn_acc_test = knn.score(x_test, y_test)\n",
    "knn_acc_train = knn.score(x_train, y_train)\n",
    "\n",
    "# Cross-Validation\n",
    "cv_knn = cross_val_score(knn, x, y, cv=3)\n",
    "\n",
    "# Printing Results\n",
    "print(\"K-Nearest Neighbors Accuracy on Test Set:\", knn_acc_test)\n",
    "print(\"K-Nearest Neighbors Accuracy on Training Set:\", knn_acc_train)\n",
    "print(\"K-Nearest Neighbors Cross-Validation Scores:\", cv_knn)\n",
    "print(\"K-Nearest Neighbors Cross-Validation Mean Score:\", cv_knn.mean())\n",
    "print(\"K-Nearest Neighbors Cross-Validation Standard Deviation:\", cv_knn.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf5bae7",
   "metadata": {},
   "source": [
    "# AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "225acae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Accuracy on Test Set: 0.8888888888888888\n",
      "AdaBoost Accuracy on Training Set: 0.9758064516129032\n",
      "AdaBoost Cross-Validation Scores: [0.88333333 0.84745763 0.86440678]\n",
      "AdaBoost Cross-Validation Mean Score: 0.865065913370998\n",
      "AdaBoost Cross-Validation Standard Deviation: 0.014653609726762409\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# Loading the dataset\n",
    "x, y = load_wine(return_X_y=True)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, train_size=0.7)\n",
    "\n",
    "# AdaBoost\n",
    "adaboost = AdaBoostClassifier()\n",
    "adaboost.fit(x_train, y_train)\n",
    "\n",
    "# Accuracy Scores\n",
    "adaboost_acc_test = adaboost.score(x_test, y_test)\n",
    "adaboost_acc_train = adaboost.score(x_train, y_train)\n",
    "\n",
    "# Cross-Validation\n",
    "cv_adaboost = cross_val_score(adaboost, x, y, cv=3)\n",
    "\n",
    "# Printing Results\n",
    "print(\"AdaBoost Accuracy on Test Set:\", adaboost_acc_test)\n",
    "print(\"AdaBoost Accuracy on Training Set:\", adaboost_acc_train)\n",
    "print(\"AdaBoost Cross-Validation Scores:\", cv_adaboost)\n",
    "print(\"AdaBoost Cross-Validation Mean Score:\", cv_adaboost.mean())\n",
    "print(\"AdaBoost Cross-Validation Standard Deviation:\", cv_adaboost.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e974d76",
   "metadata": {},
   "source": [
    "# With Ratio 80 - 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6f1d8c",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1b5514a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy on Test Set: 0.7777777777777778\n",
      "SVM Accuracy on Training Set: 0.7183098591549296\n",
      "SVM Cross-Validation Scores: [0.63888889 0.61111111 0.63888889 0.68571429 0.74285714]\n",
      "SVM Cross-Validation Scores percentage : [63.88888889 61.11111111 63.88888889 68.57142857 74.28571429]\n",
      "SVM Cross-Validation Mean Score: 0.6634920634920635\n",
      "SVM Cross-Validation Standard Deviation: 0.04636170738133653\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# Loading the dataset\n",
    "x, y = load_wine(return_X_y=True)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, train_size=0.8)\n",
    "\n",
    "# Support Vector Machine (SVM)\n",
    "clf_svm = SVC()\n",
    "clf_svm.fit(x_train, y_train)\n",
    "\n",
    "# Accuracy Scores\n",
    "svm_acc_test = clf_svm.score(x_test, y_test)\n",
    "svm_acc_train = clf_svm.score(x_train, y_train)\n",
    "\n",
    "# Cross-Validation\n",
    "cv_svm = cross_val_score(clf_svm, x, y, cv=5)\n",
    "\n",
    "# Printing Results\n",
    "print(\"SVM Accuracy on Test Set:\", svm_acc_test)\n",
    "print(\"SVM Accuracy on Training Set:\", svm_acc_train)\n",
    "print(\"SVM Cross-Validation Scores:\", cv_svm)\n",
    "print(\"SVM Cross-Validation Scores percentage :\", cv_svm * 100)\n",
    "print(\"SVM Cross-Validation Mean Score:\", cv_svm.mean())\n",
    "print(\"SVM Cross-Validation Standard Deviation:\", cv_svm.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de6dfb0",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "28f312e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy on Test Set: 0.9722222222222222\n",
      "Decision Tree Accuracy on Training Set: 1.0\n",
      "Decision Tree Cross-Validation Scores: [0.94444444 0.83333333 0.86111111 0.91428571 0.85714286]\n",
      "Decision Tree Cross-Validation Mean Score: 0.882063492063492\n",
      "Decision Tree Cross-Validation Standard Deviation: 0.0409006687162463\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Loading the dataset\n",
    "x, y = load_wine(return_X_y=True)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, train_size=0.8)\n",
    "\n",
    "# Decision Tree\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(x_train, y_train)\n",
    "\n",
    "# Accuracy Scores\n",
    "dt_acc_test = dt.score(x_test, y_test)\n",
    "dt_acc_train = dt.score(x_train, y_train)\n",
    "\n",
    "# Cross-Validation\n",
    "cv_dt = cross_val_score(dt, x, y, cv=5)\n",
    "\n",
    "# Printing Results\n",
    "print(\"Decision Tree Accuracy on Test Set:\", dt_acc_test)\n",
    "print(\"Decision Tree Accuracy on Training Set:\", dt_acc_train)\n",
    "print(\"Decision Tree Cross-Validation Scores:\", cv_dt)\n",
    "print(\"Decision Tree Cross-Validation Mean Score:\", cv_dt.mean())\n",
    "print(\"Decision Tree Cross-Validation Standard Deviation:\", cv_dt.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7172c44",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6cbddcb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy on Test Set: 0.9166666666666666\n",
      "Logistic Regression Accuracy on Training Set: 0.9859154929577465\n",
      "Logistic Regression Cross-Validation Scores: [0.76666667 0.94915254 1.        ]\n",
      "Logistic Regression Cross-Validation Mean Score: 0.9052730696798493\n",
      "Logistic Regression Cross-Validation Standard Deviation: 0.1001837219112134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arooj\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Arooj\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Arooj\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Arooj\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# Loading the dataset\n",
    "x, y = load_wine(return_X_y=True)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, train_size=0.8)\n",
    "\n",
    "# Logistic Regression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(x_train, y_train)\n",
    "\n",
    "# Accuracy Scores\n",
    "lr_acc_test = lr.score(x_test, y_test)\n",
    "lr_acc_train = lr.score(x_train, y_train)\n",
    "\n",
    "# Cross-Validation\n",
    "cv_lr = cross_val_score(lr, x, y, cv=3)\n",
    "\n",
    "# Printing Results\n",
    "print(\"Logistic Regression Accuracy on Test Set:\", lr_acc_test)\n",
    "print(\"Logistic Regression Accuracy on Training Set:\", lr_acc_train)\n",
    "print(\"Logistic Regression Cross-Validation Scores:\", cv_lr)\n",
    "print(\"Logistic Regression Cross-Validation Mean Score:\", cv_lr.mean())\n",
    "print(\"Logistic Regression Cross-Validation Standard Deviation:\", cv_lr.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b05c21a",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c3a7859b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy on Test Set: 0.9722222222222222\n",
      "Random Forest Accuracy on Training Set: 1.0\n",
      "Random Forest Cross-Validation Scores: [0.93333333 0.89830508 0.98305085]\n",
      "Random Forest Cross-Validation Mean Score: 0.9382297551789077\n",
      "Random Forest Cross-Validation Standard Deviation: 0.03477012400103735\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# Loading the dataset\n",
    "x, y = load_wine(return_X_y=True)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, train_size=0.8)\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Accuracy Scores\n",
    "rf_acc_test = rf.score(x_test, y_test)\n",
    "rf_acc_train = rf.score(x_train, y_train)\n",
    "\n",
    "# Cross-Validation\n",
    "cv_rf = cross_val_score(rf, x, y, cv=3)\n",
    "\n",
    "# Printing Results\n",
    "print(\"Random Forest Accuracy on Test Set:\", rf_acc_test)\n",
    "print(\"Random Forest Accuracy on Training Set:\", rf_acc_train)\n",
    "print(\"Random Forest Cross-Validation Scores:\", cv_rf)\n",
    "print(\"Random Forest Cross-Validation Mean Score:\", cv_rf.mean())\n",
    "print(\"Random Forest Cross-Validation Standard Deviation:\", cv_rf.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055baa63",
   "metadata": {},
   "source": [
    "# GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "16fc19b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy on Test Set: 0.9166666666666666\n",
      "Naive Bayes Accuracy on Training Set: 0.9859154929577465\n",
      "Naive Bayes Cross-Validation Scores: [0.95       0.96610169 0.96610169]\n",
      "Naive Bayes Cross-Validation Mean Score: 0.9607344632768361\n",
      "Naive Bayes Cross-Validation Standard Deviation: 0.007590411775448826\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# Loading the dataset\n",
    "x, y = load_wine(return_X_y=True)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, train_size=0.8)\n",
    "\n",
    "# Naive Bayes\n",
    "nb = GaussianNB()\n",
    "nb.fit(x_train, y_train)\n",
    "\n",
    "# Accuracy Scores\n",
    "nb_acc_test = nb.score(x_test, y_test)\n",
    "nb_acc_train = nb.score(x_train, y_train)\n",
    "\n",
    "# Cross-Validation\n",
    "cv_nb = cross_val_score(nb, x, y, cv=3)\n",
    "\n",
    "# Printing Results\n",
    "print(\"Naive Bayes Accuracy on Test Set:\", nb_acc_test)\n",
    "print(\"Naive Bayes Accuracy on Training Set:\", nb_acc_train)\n",
    "print(\"Naive Bayes Cross-Validation Scores:\", cv_nb)\n",
    "print(\"Naive Bayes Cross-Validation Mean Score:\", cv_nb.mean())\n",
    "print(\"Naive Bayes Cross-Validation Standard Deviation:\", cv_nb.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e798bb69",
   "metadata": {},
   "source": [
    "# KNeighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fbf6790e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors Accuracy on Test Set: 0.8055555555555556\n",
      "K-Nearest Neighbors Accuracy on Training Set: 0.7887323943661971\n",
      "K-Nearest Neighbors Cross-Validation Scores: [0.61666667 0.61016949 0.76271186]\n",
      "K-Nearest Neighbors Cross-Validation Mean Score: 0.6631826741996234\n",
      "K-Nearest Neighbors Cross-Validation Standard Deviation: 0.07042773174762534\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# Loading the dataset\n",
    "x, y = load_wine(return_X_y=True)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, train_size=0.8)\n",
    "\n",
    "# K-Nearest Neighbors (KNN)\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(x_train, y_train)\n",
    "\n",
    "# Accuracy Scores\n",
    "knn_acc_test = knn.score(x_test, y_test)\n",
    "knn_acc_train = knn.score(x_train, y_train)\n",
    "\n",
    "# Cross-Validation\n",
    "cv_knn = cross_val_score(knn, x, y, cv=3)\n",
    "\n",
    "# Printing Results\n",
    "print(\"K-Nearest Neighbors Accuracy on Test Set:\", knn_acc_test)\n",
    "print(\"K-Nearest Neighbors Accuracy on Training Set:\", knn_acc_train)\n",
    "print(\"K-Nearest Neighbors Cross-Validation Scores:\", cv_knn)\n",
    "print(\"K-Nearest Neighbors Cross-Validation Mean Score:\", cv_knn.mean())\n",
    "print(\"K-Nearest Neighbors Cross-Validation Standard Deviation:\", cv_knn.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f2c6c8",
   "metadata": {},
   "source": [
    "# AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cad78819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Accuracy on Test Set: 0.8611111111111112\n",
      "AdaBoost Accuracy on Training Set: 0.9295774647887324\n",
      "AdaBoost Cross-Validation Scores: [0.88333333 0.84745763 0.86440678]\n",
      "AdaBoost Cross-Validation Mean Score: 0.865065913370998\n",
      "AdaBoost Cross-Validation Standard Deviation: 0.014653609726762409\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# Loading the dataset\n",
    "x, y = load_wine(return_X_y=True)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, train_size=0.8)\n",
    "\n",
    "# AdaBoost\n",
    "adaboost = AdaBoostClassifier()\n",
    "adaboost.fit(x_train, y_train)\n",
    "\n",
    "# Accuracy Scores\n",
    "adaboost_acc_test = adaboost.score(x_test, y_test)\n",
    "adaboost_acc_train = adaboost.score(x_train, y_train)\n",
    "\n",
    "# Cross-Validation\n",
    "cv_adaboost = cross_val_score(adaboost, x, y, cv=3)\n",
    "\n",
    "# Printing Results\n",
    "print(\"AdaBoost Accuracy on Test Set:\", adaboost_acc_test)\n",
    "print(\"AdaBoost Accuracy on Training Set:\", adaboost_acc_train)\n",
    "print(\"AdaBoost Cross-Validation Scores:\", cv_adaboost)\n",
    "print(\"AdaBoost Cross-Validation Mean Score:\", cv_adaboost.mean())\n",
    "print(\"AdaBoost Cross-Validation Standard Deviation:\", cv_adaboost.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b48b812",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
